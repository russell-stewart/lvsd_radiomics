{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Classification\n",
    "## Purpose\n",
    "This notebook performs training and internal validation for the LVSD etiology classifier.\n",
    "\n",
    "## Prerequisites\n",
    "- Extracted wall thicknesses and chamber volumes as computed by `ukbb_cardiac`\n",
    "- Radiomic features extracted using `pyradiomics` from segmented T1 map images (see `ValidateMasksExtractFeatures.ipynb`)\n",
    "- Heart failure etiology classifications (see `HFClassification.py`)\n",
    "    - Include covariates extracted from UK Biobank's phenotype tables, as named in [their public Showcase documentation](https://biobank.ndph.ox.ac.uk/showcase/)\n",
    "- Python environment (3.9.x) with dependencies specified in `requirements.txt`\n",
    "\n",
    "## Local Dependencies\n",
    "- `FeatureSelector.py`: Pipeline module responsible for selecting a minimum number of features through RFECV and constraining to a maximum number of features through heirarchical clustering\n",
    "- `HFClassification.py`: Enumeration of etiologic diagnoses considered in this study.\n",
    "## Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import RocCurveDisplay, f1_score, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from MLstatkit.stats import Bootstrapping\n",
    "from HFClassification import HFClassification\n",
    "from FeatureSelector import FeatureSelector\n",
    "shmolli_extracted_features_path = ''#path to CSV contianing extracted radiomic features from T1 map, listed by EID. See ValidateMasksExtractFeatures.ipynb.\n",
    "excluded_by_bad_mri_path = ''#list any MRI to exclude over segmentation quality\n",
    "phenotypes_path = ''#table of participant EIDs and their corresponding HFClassification diagnoses\n",
    "short_axis_path = ''#results generated by ukbb_cardiac segmentation\n",
    "\n",
    "shmolli_extracted_features = pd.read_csv(shmolli_extracted_features_path , low_memory=False)\n",
    "excluded_by_bad_mri = pd.read_csv(excluded_by_bad_mri_path)\n",
    "phenotypes = pd.read_csv(phenotypes_path)\n",
    "short_axis = pd.read_csv(short_axis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Records of blood pressures in UKBB are exploded across 16 tabular columns. We just want one reading for systolic BP and one reading for diastolic BP as aquired at the start of an imaging appointment. We will prefer manual readings over automated readings if both are available, due to higher accuracy\n",
    "- Drop patients who do not have valid MRI or whose MRI were deemed of insufficient segmentation quality on review. Select the earliest avialable pair of MRI from each patient.\n",
    "- Merge tables imported above together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes['systolic_bp'] = phenotypes.p93_i2_a0.fillna(phenotypes.p4080_i2_a0).fillna(phenotypes.p93_i3_a0).fillna(phenotypes.p4080_i3_a0)\n",
    "phenotypes['diastolic_bp'] = phenotypes.p94_i2_a0.fillna(phenotypes.p4079_i2_a0).fillna(phenotypes.p94_i3_a0).fillna(phenotypes.p4079_i3_a0)\n",
    "\n",
    "quality_or_segmentation_failures =excluded_by_bad_mri[~excluded_by_bad_mri.passable_shmolli_quality].mask_path.str.replace('_myocardium.png' , '.dcm').reset_index(drop=True)\n",
    "shmolli_extracted_features.drop(columns = quality_or_segmentation_failures , inplace=True)\n",
    "\n",
    "shmolli_extracted_T = shmolli_extracted_features.T\n",
    "shmolli_extracted_T.columns = shmolli_extracted_T.iloc[0]\n",
    "shmolli_extracted_T = shmolli_extracted_T.reset_index().sort_values(by = 'index')\n",
    "shmolli_extracted_T = shmolli_extracted_T.drop(index = shmolli_extracted_T.loc[shmolli_extracted_T['index'] == 'Unnamed: 0'].index)\n",
    "shmolli_extracted_T['eid'] = shmolli_extracted_T['index'].apply(lambda s : int(s.split('/')[-2]))\n",
    "shmolli_extracted_T.drop_duplicates(subset = 'eid' , keep = 'first' , inplace = True)\n",
    "shmolli_extracted_T.drop(columns = [c for c in shmolli_extracted_T.columns if 'diagnostic' in c])\n",
    "\n",
    "print(f'Number of patients in eligible patient phenotype CSV: {phenotypes.shape[0]}')\n",
    "print(f'...who also had a ShMOLLI MRI of passable quality which was segmented successfully: {shmolli_extracted_T.shape[0]}')\n",
    "\n",
    "short_axis.sort_values(by = ['eid' , 'cMRI_date'] , inplace = True)\n",
    "short_axis.drop_duplicates(subset = ['eid','cMRI_date'] , keep = 'first' , inplace = True)\n",
    "short_axis.drop_duplicates(subset = ['eid'] , keep = 'first' , inplace = True)\n",
    "short_axis = short_axis.drop(columns = ['sex','dob_year','dob_month','height_cm','weight_kg','ethnicity','cMRI_date','hf_date','hf_codes'])\n",
    "\n",
    "phenotypes['HFClassification'] = phenotypes.class_int.apply(lambda i : HFClassification(i))\n",
    "phenotypes['class_vector'] = phenotypes.HFClassification.apply(lambda h : h.__vector__())\n",
    "full_dataset = (phenotypes.merge(shmolli_extracted_T , how = 'inner' , on = 'eid')).merge(short_axis , how = 'inner' , on = 'eid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Covariates and Features; Ensure All are Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covariates = [\n",
    "    'p21003_i2',#age at first imaging visit\n",
    "    'p21001_i2',#bmi at first imaging visit\n",
    "    'p30030_i2',#hematocrit at imaging visit\n",
    "    'p30030_i0',#hematocrit as measured at first Biobank visit\n",
    "    'p30030_i1',#hematocrit as measured at second Biobank visit\n",
    "    'systolic_bp',\n",
    "    'diastolic_bp',\n",
    "    'p31',#sex\n",
    "]\n",
    "\n",
    "shmolli_features = [i for i in shmolli_extracted_T.columns if i != 'index' and 'diagnostics' not in i and i != 'eid']\n",
    "short_axis_features = [i for i in short_axis.columns if i != 'index' and i != 'eid']\n",
    "all_features = covariates + short_axis_features + shmolli_features\n",
    "\n",
    "#Make sure all of our fields are numeric and not entirely empty\n",
    "full_dataset[['p53_i0','p53_i1','imaging_date','p53_i3']] = \\\n",
    "    full_dataset[['p53_i0','p53_i1','imaging_date','p53_i3']].apply(lambda t : pd.to_datetime(t).astype(np.int64) if ~pd.isna(t).any() else None)\n",
    "full_dataset[all_features] = full_dataset[all_features].apply(pd.to_numeric)\n",
    "covariates = [c for c in covariates if ~pd.isna(full_dataset[c]).all()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chose Egiologies for your Classifier to Identify\n",
    "- List the `HFClassification`s which you wish your model to differentiate.\n",
    "    - If you have an intuition of good chain ordering for your diagnostic labels, list your labels here in preferred sort order. This order will inform classifier chain ordering. (The ordering below is based on the clinical definition as ICM and NICM as distinct etiologies, with further subtypes representing subtypes of NICM.)\n",
    "- These will be assigned binarized labels, with multi-output encoding.\n",
    "- Everything else in the training set will be assigned $y=\\boldsymbol{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain_ordered_classifications = [HFClassification.ICM , HFClassification.ARRHYTHMIA , HFClassification.HYPERTENSIVE]\n",
    "\n",
    "labels_to_binarize = np.array(chain_ordered_classifications).reshape(1,-1)\n",
    "Y = (np.expand_dims(full_dataset.HFClassification , axis = 1) & labels_to_binarize).astype(bool).astype(np.uint8)\n",
    "\n",
    "has_classification = Y.sum(axis = 1) > 0\n",
    "full_dataset = full_dataset[has_classification]\n",
    "Y = Y[has_classification]\n",
    "\n",
    "print('Encoding of chosen classifications:')\n",
    "print(labels_to_binarize.squeeze())\n",
    "unique_rows , counts = np.unique(Y , axis = 0 , return_counts = True)\n",
    "print('Number of instances of each encoding:')\n",
    "for row , count in zip(unique_rows , counts):\n",
    "    print(f'Encoding {row} {\" | \".join([labels_to_binarize[0,i].__str__() for i in np.where(row)[0]])}: {count} instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "- We'll split our training from our test data now.\n",
    "- Test data will be reserved for internal validation of our finalized classifier.\n",
    "- Stratified K-folding will be used to split training and validation sets as we both select features and train our classifier below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_size = 0.2#percent test for your train test split\n",
    "random_state = 888#will be used for all random number generation\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(\n",
    "    full_dataset[all_features] ,\n",
    "    Y ,\n",
    "    test_size = test_size ,\n",
    "    stratify = Y ,\n",
    "    random_state = random_state\n",
    ")\n",
    "\n",
    "print(f'Training X shape: {X_train.shape}')\n",
    "print('Training class counts:')\n",
    "unique_rows , counts = np.unique(Y_train , axis = 0 , return_counts = True)\n",
    "for row , count in zip(unique_rows , counts):\n",
    "    print(f'Encoding {row} {\" | \".join([labels_to_binarize[0,i].__str__() for i in np.where(row)[0]])}: {count} instances')\n",
    "    \n",
    "print(f'Test X shape: {X_test.shape}')\n",
    "print('Test class counts:')\n",
    "unique_rows , counts = np.unique(Y_test , axis = 0 , return_counts = True)\n",
    "for row , count in zip(unique_rows , counts):\n",
    "    print(f'Encoding {row} {\" | \".join([labels_to_binarize[0,i].__str__() for i in np.where(row)[0]])}: {count} instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Pipeline on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters for preprocessing and feature selection\n",
    "min_features_to_select = 20#min number of features to pass from feature selection\n",
    "n_jobs = -1#set to n cpu cores\n",
    "cross_correlation_threshold = 0.8#for heirarchical clustering\n",
    "stratified_k_fold_n_splits = 5\n",
    "RFECV_threshold = 1\n",
    "iterative_imputer_max_iter = 100000\n",
    "scoring_metric = 'roc_auc' #we're decomposing this problem into m binary classification problems, so no need for a multilabel scoring metric\n",
    "\n",
    "#define pipeline components\n",
    "#imputer acting only on the covariates\n",
    "imputer = IterativeImputer(max_iter=iterative_imputer_max_iter, random_state=random_state)\n",
    "column_subset_imputer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('imputer', imputer , covariates),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "#standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#rfecv_model = RandomForestClassifier(class_weight='balanced',random_state=random_state,n_jobs=n_jobs)\n",
    "rfecv_model = LogisticRegression(class_weight='balanced',C=0.3)\n",
    "\n",
    "feature_selector = FeatureSelector(\n",
    "    estimator = rfecv_model ,\n",
    "    step = 1 ,\n",
    "    cv = StratifiedKFold(n_splits = stratified_k_fold_n_splits) ,\n",
    "    scoring = scoring_metric,\n",
    "    min_features_to_select=min_features_to_select ,\n",
    "    n_jobs = n_jobs\n",
    ")\n",
    "#calibrated classifier; logistic regression with balanced class weight chosen as the best option from a grid search\n",
    "#on ICM and ARRHYTHMIA tasks using this pipeline\n",
    "base_model = CalibratedClassifierCV(LogisticRegression(class_weight='balanced') , cv = StratifiedKFold(n_splits = stratified_k_fold_n_splits))\n",
    "binary_pipeline = Pipeline(steps=[\n",
    "    ('feature_selector' , feature_selector),\n",
    "    ('classifier', base_model)])\n",
    "\n",
    "#build a classifier chain\n",
    "classifier_chain = ClassifierChain(binary_pipeline ,\n",
    "                        order=None,\n",
    "                        cv = None,\n",
    "                        chain_method='predict_proba',\n",
    "                        random_state=random_state)\n",
    "\n",
    "#construct pipeline\n",
    "myfit = Pipeline(steps=[\n",
    "    ('imputer', column_subset_imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('classifier_chain', classifier_chain),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    myfit.fit(X_train , Y_train)\n",
    "display(myfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Optimal Threshold by Diagnosis\n",
    "- 0.5 may not represent an accurate significance cutoff for all etiologies due to our high class imbalance.\n",
    "- To address this, compute a significance cutoff which maximized model F1 statistic performance in the training data set.\n",
    "- Optimized thresholds as used in poster presentation:\n",
    "    - ICM: 0.43\n",
    "    - ARRHYTHMIA: 0.31\n",
    "    - Hypertensive: 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_threshold(y_test:np.ndarray , y_prob:np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    `get_optimal_threshold`\n",
    "    Maximize the F1 by chosing the best cutoff on an ROC curve.\n",
    "    Arguments:\n",
    "    y_test: array of binary true labels (m observations * 1 column)\n",
    "    y_prob: array of predicted probabilities (m observations * 1 column)\n",
    "    Returns:\n",
    "    Significance cutoff which maximizes F1, balancing precision and recall\n",
    "    \"\"\"\n",
    "    best_threshold=-1\n",
    "    best_f1=-1\n",
    "    for threshold in np.arange(0.0, 1.0, 0.01):\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold\n",
    "\n",
    "Y_fit = myfit.predict_proba(X_train)\n",
    "optimal_thresholds = [None for i in range(0 , Y_fit.shape[1])]\n",
    "for i in range(0 , Y_fit.shape[1]):\n",
    "    optimal_thresholds[i] = get_optimal_threshold(\n",
    "        np.array(Y_train[:,i]) ,\n",
    "        np.array(Y_fit[:,i])\n",
    "    )\n",
    "print('Optimized thresholds:')\n",
    "display(pd.DataFrame({'Class':chain_ordered_classifications , 'Threshold':optimal_thresholds}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and Save Feature Importances\n",
    "- We'll visualize the sources of our features and their importance rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.set_context('talk')\n",
    "plt.figure(figsize = (15,6))\n",
    "colorblind_palette = sns.color_palette(\"Set2\")\n",
    "color_dict = {\n",
    "    \"Cine\": colorblind_palette[0],\n",
    "    \"Covariate\": colorblind_palette[1],\n",
    "    \"T1 Map\": colorblind_palette[2],\n",
    "    \"Other Class\" : colorblind_palette[3],\n",
    "}\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color=color_dict[\"Cine\"], label='Cine'),\n",
    "    mpatches.Patch(color=color_dict[\"Covariate\"], label='Covariate'),\n",
    "    mpatches.Patch(color=color_dict[\"T1 Map\"], label='T1 Map'),\n",
    "    mpatches.Patch(color=color_dict[\"Other Class\"], label=\"Other Etiology\\nDecision\")\n",
    "]\n",
    "\n",
    "features = myfit.named_steps['imputer'].get_feature_names_out()\n",
    "for i , p in enumerate(myfit.named_steps['classifier_chain'].estimators_):\n",
    "    if i > 0:\n",
    "        features = np.append(features , f'{chain_ordered_classifications[i-1]} Decision')\n",
    "    myclass = labels_to_binarize[0,i].__str__()\n",
    "    chosen = p.named_steps['feature_selector'].get_support()\n",
    "    ranks = p.named_steps['feature_selector'].ranking_\n",
    "    rankings_df = pd.DataFrame({'feature':features,'was_chosen':chosen,'rank':ranks})\n",
    "    rankings_df['Source'] = rankings_df['feature'].apply(lambda s : \"Cine\" if '(' in s else \"Covariate\" if 'imputer' in s else 'Other Class' if 'Decision' in s else \"T1 Map\")\n",
    "    rankings_df['feature'] = rankings_df['feature'].apply(lambda s : s.split('__')[-1].replace('_' , ' ').split('( ')[0])\n",
    "    rankings_df['color'] = rankings_df['Source'].apply(lambda s : color_dict[s])\n",
    "    rankings_df.sort_values(by = 'rank' , inplace=True,ascending=False)\n",
    "    plt.subplot(i//3+1,3,i+1)\n",
    "    plt.axis('equal')\n",
    "    plt.barh(y = rankings_df.loc[rankings_df.was_chosen , 'feature'] , width = rankings_df.loc[rankings_df.was_chosen , 'rank'], color = rankings_df.loc[rankings_df.was_chosen , 'color'])\n",
    "    plt.title(myclass)\n",
    "    plt.xlabel('Importance Rank')\n",
    "    plt.ylabel(f'{rankings_df.was_chosen.sum()} Features Selected from {rankings_df.shape[0]}')\n",
    "    plt.xlim(0,20)\n",
    "    if i == 1:\n",
    "        plt.legend(handles=legend_handles, title='Feature Source', loc='best')\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    rankings_df.to_csv(f'{myclass}_features.csv')\n",
    "plt.savefig('feature_importance.svg',format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code to Plot Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_model_fit(y_test_in , y_pred_in , classes:list , title:str) -> None:\n",
    "    \"\"\"\n",
    "    `plot_model_fit`\n",
    "    Draws ROC curves and calibration curves for each classification, given classifier results.\n",
    "    Arguments:\n",
    "    y_test_in: The ground-truth labels for y_test\n",
    "    y_pred_in: The predicted labels for x_test from a classifier.\n",
    "    classes: Names with which to label each class\n",
    "    title: Title for the subplots\n",
    "    \"\"\"\n",
    "    sns.set_theme(style='darkgrid', palette='colorblind', context='talk')\n",
    "\n",
    "    y_test = np.array(y_test_in)\n",
    "    y_pred = np.array(y_pred_in)\n",
    "    fig , [ax1 , ax2] = plt.subplots(1,2,figsize=(12,8))\n",
    "    i = 0\n",
    "    for class_of_interest , mycolor in zip(classes ,  sns.color_palette('colorblind')[0:len(classes)]):\n",
    "        plt.subplot(1,2,1)\n",
    "        my_display = RocCurveDisplay.from_predictions(\n",
    "            y_test[:,i],\n",
    "            y_pred[:,i],\n",
    "            ax = ax1,\n",
    "            name = class_of_interest,\n",
    "            color = mycolor,\n",
    "        );\n",
    "        ax1 = plt.gca()\n",
    "        ax1.set(\n",
    "            xlabel=\"False Positive Rate\",\n",
    "            ylabel=\"True Positive Rate\",\n",
    "            title=f\"Receiver Operating Characteristic:\\n{title}\",\n",
    "        );\n",
    "        ax1.plot([0, 1], [0, 1], linestyle='--', color='#444455')\n",
    "        ax1.set_aspect('equal', adjustable='box')\n",
    "        prob_true , prob_pred = calibration_curve(\n",
    "            y_test[:,i],\n",
    "            y_pred[:,i],\n",
    "            n_bins=4,\n",
    "        )\n",
    "        sort_key = np.argsort(prob_true)\n",
    "        plt.subplot(1,2,2)\n",
    "        ax2 = plt.gca()\n",
    "        plt.plot(\n",
    "            prob_true[sort_key] ,\n",
    "            prob_pred[sort_key] ,\n",
    "            linestyle = '-' ,\n",
    "            marker = '.',\n",
    "            color = mycolor\n",
    "        )\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(0,1)\n",
    "        ax2.plot([0, 1], [0, 1], linestyle='--', color='#444455')\n",
    "        ax2.set_title(f'Calibration Curve:\\n{title}')\n",
    "        ax2.set_xlabel('Predicted Probability')\n",
    "        ax2.set_ylabel('Observed Probability')\n",
    "        ax2.set_aspect('equal', adjustable='box')\n",
    "        i+=1\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internally validate the classifier; plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_score = np.array(myfit.predict_proba(X_test))\n",
    "\n",
    "Y_score_df = pd.DataFrame(Y_score ,#transpose to get the probability of each class (col) being true for each observation (row)\n",
    "                          index=X_test.index,\n",
    "                          columns=labels_to_binarize.squeeze())\n",
    "plot_model_fit(Y_test ,\n",
    "               Y_score_df ,\n",
    "               labels_to_binarize.squeeze(),\n",
    "               title = 'Internal Validation')\n",
    "plt.savefig('ROC.svg',format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot Confusion Matrix for this Internal Validation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='dark', palette='colorblind', context='poster')\n",
    "\n",
    "Y_score_list = pd.DataFrame(myfit.predict(X_test) , columns = Y_score_df.columns).apply(lambda h : h.__str__()).tolist()\n",
    "Y_test_df = pd.DataFrame(Y_test , columns = Y_score_df.columns)\n",
    "\n",
    "m =  Y_score_df.shape[1]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for etiology , threshold , i in zip(Y_score_df.columns , optimal_thresholds , range(0 , m)):\n",
    "    plt.subplot(np.ceil(m/3).astype(int),3,i+1)\n",
    "    \n",
    "    mtx = pd.DataFrame(confusion_matrix(\n",
    "            Y_test_df[etiology],\n",
    "            Y_score_df[etiology] > optimal_thresholds[i],\n",
    "            normalize='true',\n",
    "    ))\n",
    "    mtx.index = ['Patient (-)' , 'Patient (+)']\n",
    "    mtx.columns = ['Model (-)' , 'Model (+)']\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"white\", sns.color_palette('colorblind')[i]])\n",
    "    sns.heatmap(mtx ,\n",
    "            cmap = cmap,\n",
    "            vmin = 0,\n",
    "            vmax = 1,\n",
    "            annot=True,\n",
    "            cbar=False\n",
    "        )\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.title(etiology)\n",
    "plt.savefig('confusion.svg',format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Confidence Intervals for AUCs\n",
    "- (We'll compute both a micro-averaged AUC and individual AUCs for each etiology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trueval = Y_test.ravel()\n",
    "prob_A = Y_score.ravel()\n",
    "stats = pd.DataFrame({'statistic':[] , 'expected':[] , 'lower bound':[] , 'upper bound':[]})\n",
    "for stat in ['roc_auc']:\n",
    "    e , lower , upper = Bootstrapping(trueval , prob_A , stat, average='micro')\n",
    "    stats.loc[len(stats)] = {'statistic':stat , 'expected':e , 'lower bound':lower , 'upper bound':upper}\n",
    "print('Micro-Averaged AUC')\n",
    "display(stats)\n",
    "\n",
    "for col in Y_score_df.columns:\n",
    "    trueval = np.array(Y_test_df[col].tolist())\n",
    "    prob_A = np.array(Y_score_df[col].tolist())\n",
    "    stats = pd.DataFrame({'statistic':[] , 'expected':[] , 'lower bound':[] , 'upper bound':[]})\n",
    "    print(f'AUC for {col}')\n",
    "    for stat in ['roc_auc']:\n",
    "        e , lower , upper = Bootstrapping(trueval , prob_A , stat, average='micro')\n",
    "        stats.loc[len(stats)] = {'statistic':stat , 'expected':e , 'lower bound':lower , 'upper bound':upper}\n",
    "        display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model We've Trained\n",
    "- Trained model as used in poster presentation is included in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(myfit, 'Multiclass_b_chain_v1.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
